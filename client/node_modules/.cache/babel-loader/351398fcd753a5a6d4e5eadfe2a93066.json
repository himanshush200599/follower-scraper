{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime-corejs2/regenerator\";\nimport _asyncToGenerator from \"@babel/runtime-corejs2/helpers/esm/asyncToGenerator\";\nimport _slicedToArray from \"@babel/runtime-corejs2/helpers/esm/slicedToArray\";\nvar _jsxFileName = \"/home/nitin/projects/web-scraper/client/components/Page.js\";\nimport React from \"react\";\nimport { useEffect, useState } from \"react\";\nimport { ScrapeProvider } from \"./ScrapeContext\";\n\nfunction useScrapes() {\n  var _useState = useState({\n    twitter: [],\n    instagram: []\n  }),\n      _useState2 = _slicedToArray(_useState, 2),\n      scrapes = _useState2[0],\n      setScrapes = _useState2[1];\n\n  useEffect(function () {\n    _asyncToGenerator(\n    /*#__PURE__*/\n    _regeneratorRuntime.mark(function _callee() {\n      var res, data;\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              console.log(\"Mounting or updating...\");\n              _context.next = 3;\n              return fetch(\"http://localhost:5000/data\");\n\n            case 3:\n              res = _context.sent;\n              _context.next = 6;\n              return res.json();\n\n            case 6:\n              data = _context.sent;\n              setScrapes(data);\n\n            case 8:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee);\n    }))();\n  }, []);\n  return scrapes;\n}\n\nexport default function Page(_ref2) {\n  var children = _ref2.children;\n  var scrapes = useScrapes();\n  console.log(scrapes);\n  return React.createElement(ScrapeProvider, {\n    value: {\n      scrapes: scrapes\n    },\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 25\n    },\n    __self: this\n  }, React.createElement(\"div\", {\n    className: \"page\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 30\n    },\n    __self: this\n  }, children));\n}","map":{"version":3,"sources":["/home/nitin/projects/web-scraper/client/components/Page.js"],"names":["useEffect","useState","ScrapeProvider","useScrapes","twitter","instagram","scrapes","setScrapes","console","log","fetch","res","json","data","Page","children"],"mappings":";;;;;AAAA,SAASA,SAAT,EAAoBC,QAApB,QAAoC,OAApC;AAEA,SAASC,cAAT,QAA+B,iBAA/B;;AAEA,SAASC,UAAT,GAAsB;AAAA,kBACUF,QAAQ,CAAC;AACrCG,IAAAA,OAAO,EAAE,EAD4B;AAErCC,IAAAA,SAAS,EAAE;AAF0B,GAAD,CADlB;AAAA;AAAA,MACbC,OADa;AAAA,MACJC,UADI;;AAKpBP,EAAAA,SAAS,CAAC,YAAW;AACnB;AAAA;AAAA,6BAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AACCQ,cAAAA,OAAO,CAACC,GAAR,CAAY,yBAAZ;AADD;AAAA,qBAEmBC,KAAK,CAAC,4BAAD,CAFxB;;AAAA;AAEOC,cAAAA,GAFP;AAAA;AAAA,qBAGoBA,GAAG,CAACC,IAAJ,EAHpB;;AAAA;AAGOC,cAAAA,IAHP;AAICN,cAAAA,UAAU,CAACM,IAAD,CAAV;;AAJD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAD;AAMD,GAPQ,EAON,EAPM,CAAT;AAQA,SAAOP,OAAP;AACD;;AAED,eAAe,SAASQ,IAAT,QAA4B;AAAA,MAAZC,QAAY,SAAZA,QAAY;AACzC,MAAMT,OAAO,GAAGH,UAAU,EAA1B;AACAK,EAAAA,OAAO,CAACC,GAAR,CAAYH,OAAZ;AACA,SACE,oBAAC,cAAD;AACE,IAAA,KAAK,EAAE;AACLA,MAAAA,OAAO,EAAPA;AADK,KADT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAKE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAuBS,QAAvB,CALF,CADF;AASD","sourcesContent":["import { useEffect, useState } from \"react\";\n\nimport { ScrapeProvider } from \"./ScrapeContext\";\n\nfunction useScrapes() {\n  const [scrapes, setScrapes] = useState({\n    twitter: [],\n    instagram: []\n  });\n  useEffect(function() {\n    (async () => {\n      console.log(\"Mounting or updating...\");\n      const res = await fetch(\"http://localhost:5000/data\");\n      const data = await res.json();\n      setScrapes(data);\n    })();\n  }, []);\n  return scrapes;\n}\n\nexport default function Page({ children }) {\n  const scrapes = useScrapes();\n  console.log(scrapes);\n  return (\n    <ScrapeProvider\n      value={{\n        scrapes\n      }}\n    >\n      <div className=\"page\">{children}</div>\n    </ScrapeProvider>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}